{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "Yfr_Vlr8HBkt",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member  -**Kavya Reddy Chinnam\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on analyzing and predicting the stock closing prices of Yes Bank using historical stock data and various regression models. The goal is to build accurate predictive models that can estimate future closing prices based on historical open, high, and low prices.\n",
        "\n",
        "Data Loading and Preprocessing\n",
        "\n",
        "The dataset consists of daily stock prices of Yes Bank, including the columns Date, Open, High, Low, and Close prices. The data is loaded from a CSV file (data_YesBank_StockPrices.csv) into a pandas DataFrame for analysis.\n",
        "\n",
        "The Date column is converted to datetime format to allow time-series sorting and analysis. The dataset is sorted by Date to maintain chronological order, which is essential for time-dependent stock data. Basic exploratory data analysis is performed to check the dataset’s structure, missing values, and duplicates. Any rows with missing values are removed to ensure clean data for model training.\n",
        "\n",
        "Exploratory Data Analysis\n",
        "\n",
        "Several visualization techniques help understand the data:\n",
        "\n",
        "A correlation matrix is computed and visualized using a heatmap to identify relationships between features. The strong correlations observed between the Close price and other price features (Open, High, Low) justify the use of these as predictors.\n",
        "\n",
        "Scatter plots visualize the closing price over time, showing trends and variations.\n",
        "\n",
        "Box plots provide an overview of the distribution and potential outliers in the stock price features.\n",
        "\n",
        "Hypothesis testing confirms the presence of strong linear relationships between Close prices and other features, validating the use of regression models.\n",
        "\n",
        "Model Development\n",
        "\n",
        "The dataset is split into training and testing sets (80-20 split) to evaluate model performance on unseen data.\n",
        "\n",
        "Three machine learning models are developed and compared:\n",
        "\n",
        "Linear Regression: A simple model assuming a linear relationship between predictors (Open, High, Low) and the target (Close). It serves as a baseline to compare more complex models.\n",
        "\n",
        "Decision Tree Regressor: A non-linear model that splits the feature space into regions based on decision rules. GridSearchCV is used to tune hyperparameters such as maximum tree depth and minimum samples per split for better generalization and reduced overfitting.\n",
        "\n",
        "Random Forest Regressor: An ensemble model combining multiple decision trees to improve accuracy and reduce variance. Hyperparameters like the number of trees, maximum depth, and minimum samples split are optimized using GridSearchCV with cross-validation.\n",
        "\n",
        "Model Evaluation\n",
        "\n",
        "Models are evaluated using two key metrics:\n",
        "\n",
        "Mean Squared Error (MSE): Measures the average squared difference between predicted and actual closing prices. Lower values indicate better model accuracy.\n",
        "\n",
        "R-squared (R²) Score: Represents the proportion of variance in the dependent variable explained by the model. Values closer to 1 indicate better fit.\n",
        "\n",
        "The linear regression model provides a baseline R² score, while the tuned decision tree and random forest models are expected to yield improved results due to their ability to model non-linear relationships.\n",
        "\n",
        "Results\n",
        "\n",
        "The linear regression model typically performs best among the three, demonstrating superior predictive power with higher R² scores and lower MSE values on the test data.\n",
        "\n",
        "The best-performing model is selected based on the highest R² score.\n",
        "\n",
        "Model Deployment\n",
        "\n",
        "The selected best model is serialized and saved using Python’s pickle module, allowing for later reuse without retraining. This saved model can be loaded and used for real-time predictions or integration into a larger application, such as a stock forecasting tool or a financial decision support system.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The objective of the project is to develop an effective machine learning model that can predict the closing price of Yes Bank’s stock using historical stock data, including open, high, and low prices. The challenge lies in capturing the underlying patterns and relationships within the financial time-series data to provide reliable and accurate price predictions."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pickle"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df=pd.read_csv('data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Dataset shape (rows, columns):\", df.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(\"Number of duplicate rows:\", duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"Missing values:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My dataset contains 5 cloumns (Date,open,high,low,close)\n",
        "#####Date needs to be converted to datetime format to sort and visualize trends.\n",
        "#####open,high,low are higly correlated to close.\n",
        "#####close variable is used as target variable.\n",
        "#####This dataset contains 185 records.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####*Date needs to be converted to datetime format to sort and visualize trends.\n",
        "#####*The Close column is typically used as the target variable for stock price prediction.\n",
        "#####*Features like Open, High, Low are highly correlated with Close."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df['Open'].unique()\n",
        "df['Close'].unique()\n",
        "df['High'].unique()\n",
        "df['Low'].unique()\n",
        "df['Date'].unique()\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I droped empty values from dataset"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "sns.heatmap(corr_matrix, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To examine the correlation between numerical variables."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Reveals how strongly variables are related (values from -1 to 1).\n",
        "####Useful for reducing multicollinearity in models."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "print(\"scatter plot\")\n",
        "plt.scatter(df['Date'],df['Close'])\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Close Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the trend of the stock closing prices over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Shows how the stock price changes with time.\n",
        "####Helps identify upward or downward trends, spikes, or crashes.\n",
        "####Useful for detecting seasonality or volatility."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "print(\"box plot\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(data=df[['Open', 'High', 'Low', 'Close']])\n",
        "plt.title(\"Box Plot of Stock Price Features\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze the distribution and outliers of stock price features."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Quickly compares Open, High, Low, and Close prices.\n",
        "####Box plots show:\n",
        "\n",
        "Median\n",
        "\n",
        "Interquartile Range (IQR)\n",
        "\n",
        "Outliers (unusual values)\n",
        "####Useful for detecting price variability or anomalies."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Null Hypothesis: There is a strong linear relationship between open,close,high and low prices.\n",
        "####Alternative Hypothesis : There is no strong linear relationship between open,close,high,low prices."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hypothesis test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "if abs(corr_matrix['Close'][0]) > 0.8 and abs(corr_matrix['Close'][1]) > 0.8 and abs(corr_matrix['Close'][2]) > 0.8:\n",
        "    print(\" Hypothesis 1 supported: Strong linear relationships found.\")\n",
        "else:\n",
        "    print(\" Hypothesis 1 not supported: Correlations are weak.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.dropna()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used dropna to drop missing values"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Transformation"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data transformation\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values('Date')\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####splitting of data"
      ],
      "metadata": {
        "id": "1yDXoqyPnfyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=df[['Open','High','Low']]\n",
        "y=df['Close']\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "Wtn4o6cWnjmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "print(\"Linear Regression model\")\n",
        "model1=LinearRegression()\n",
        "model1.fit(x_train,y_train)\n",
        "y_pred1=model1.predict(x_test)\n",
        "mse1=mean_squared_error(y_test,y_pred1)\n",
        "r2_1=r2_score(y_test,y_pred1)\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Display"
      ],
      "metadata": {
        "id": "X0Zx4ILipJW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dates to test:\",x_test)\n",
        "\n",
        "print('actual_value:',y_test)\n",
        "\n",
        "print('predicted value:',y_pred1)\n",
        "\n",
        "print('mean squared error:',mse1)\n",
        "\n",
        "print('r2 score:',r2_1)\n"
      ],
      "metadata": {
        "id": "781Xb37KpMho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Why this model"
      ],
      "metadata": {
        "id": "ocH3xkT3pmib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression is a simple algorithm that assumes a linear relationship between input features (Open, High, Low) and the output (Close).\n",
        "\n",
        "It tries to find the best-fit line that minimizes the difference between predicted values and actual values."
      ],
      "metadata": {
        "id": "RHajP4FZppiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ML model 2"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#decision tree model2\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Decision Tree model with GridSearchCV\n",
        "print(\"Tuned Decision Tree Model\")\n",
        "param_grid_dt = {\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_dt = GridSearchCV(DecisionTreeRegressor(), param_grid_dt, cv=5, scoring='r2')\n",
        "grid_dt.fit(x_train, y_train)\n",
        "\n",
        "best_dt = grid_dt.best_estimator_\n",
        "y_pred2 = best_dt.predict(x_test)\n",
        "mse2 = mean_squared_error(y_test, y_pred2)\n",
        "r2_2 = r2_score(y_test, y_pred2)"
      ],
      "metadata": {
        "id": "GjTZ7-0CoWt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Display"
      ],
      "metadata": {
        "id": "gaVBsBz_pQ7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters (Decision Tree):\", grid_dt.best_params_)\n",
        "print(\"dates to test:\",x_test)\n",
        "print(\"actual values:\",y_test)\n",
        "print(\"predicted values:\",y_pred2)\n",
        "print(\"mean squared error:\",mse2)\n",
        "print(\"r2 score:\",r2_2)"
      ],
      "metadata": {
        "id": "n_7Az7xypSyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Why this model"
      ],
      "metadata": {
        "id": "eFrLfcDapx0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Regressor splits the data into branches based on feature values and predicts output based on decision rules.\n",
        "\n",
        "It builds a tree structure with nodes representing features and branches representing possible decisions based on those features."
      ],
      "metadata": {
        "id": "X-iwmJsJp0DV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ML model 3"
      ],
      "metadata": {
        "id": "mOkk1auVokR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "print(\"random forest model\")\n",
        "model3=RandomForestRegressor()\n",
        "model3.fit(x_train,y_train)\n",
        "y_pred3=model3.predict(x_test)\n",
        "mse3=mean_squared_error(y_test,y_pred3)\n",
        "r2_3=r2_score(y_test,y_pred3)\n"
      ],
      "metadata": {
        "id": "__pTpGkeor3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Display"
      ],
      "metadata": {
        "id": "-18LNsV8pXiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters (Random Forest):\", grid_rf.best_params_)\n",
        "print(\"dates to test:\",x_test)\n",
        "print(\"actual values:\",y_test)\n",
        "print(\"predicted values:\",y_pred2)\n",
        "print(\"mean squared error:\",mse2)\n",
        "print(\"r2 score:\",r2_2)"
      ],
      "metadata": {
        "id": "6kA1oY71peGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Why this model"
      ],
      "metadata": {
        "id": "YAmtRtp4p6MF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor is an ensemble method that combines multiple decision trees to improve accuracy and control overfitting.\n",
        "\n",
        "It creates multiple trees and aggregates their predictions, typically by averaging the results in regression tasks."
      ],
      "metadata": {
        "id": "dSVHqG8-p8dZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Hyperparameter tuning"
      ],
      "metadata": {
        "id": "WX-c3qfrXPbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV was used to optimize the performance of the Decision Tree and Random Forest models by finding the best combination of hyperparameters."
      ],
      "metadata": {
        "id": "x05JUhE6XVkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Reason for choosing that method"
      ],
      "metadata": {
        "id": "wCUXXd3HXemM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gridsearchcv is used because :\n",
        "#####Improve accuracy.\n",
        "#####To avoid over fitting and underfitting.\n",
        "#####Built in cross -validation."
      ],
      "metadata": {
        "id": "38nrMylzXi43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####which is best model?"
      ],
      "metadata": {
        "id": "1Pgi4yGeXJQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = max((r2_1, \"Linear Regression\"), (r2_2, \"Decision Tree\"), (r2_3, \"Random Forest\"))\n",
        "print(\"The best model is:\", best_model)"
      ],
      "metadata": {
        "id": "rMN2ytKvo8gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "if best_model[1] == \"Linear Regression\":\n",
        "    final_model = model1\n",
        "    filename = 'linear_regression_model.pkl'\n",
        "elif best_model[1] == \"Tuned Decision Tree\":\n",
        "    final_model = best_dt\n",
        "    filename = 'decision_tree_model.pkl'\n",
        "elif best_model[1] == \"Tuned Random Forest\":\n",
        "    final_model = best_rf\n",
        "    filename = 'random_forest_model.pkl'\n",
        "else:\n",
        "    raise ValueError(\"Unknown model type\")\n",
        "\n",
        "# Save using pickle\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(final_model, file)\n",
        "\n",
        "print(f\" Best model saved as '{filename}'\")"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File\n",
        "with open(filename, 'rb') as file:\n",
        "    loaded_model = pickle.load(file)"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project explored how machine learning can help predict Yes Bank’s stock closing prices using past price data. After cleaning and analyzing the data, i tested different models and found that the Linear regression model gave the most accurate predictions."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}